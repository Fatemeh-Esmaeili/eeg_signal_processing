{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import mne\n",
    "from pathlib import Path\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "base_path = r\"D:\\impress_project\\eeg_signals\\data\\LRMI-21679035\\organized_data_v2\"\n",
    "raw_data_dir = os.path.join(base_path, \"raw_data\")\n",
    "preprocessed_dir = os.path.join(base_path, \"paper_preprocessed\")\n",
    "output_dir = os.path.join(base_path, \"labelled_paper_preprocessed\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ================= CHANNEL INFORMATION FROM PAPER =================\n",
    "# From paper Table 2 (0-based indexing for Python)\n",
    "paper_channels = {\n",
    "    0: 'Fp1', 1: 'Fp2', 2: 'Pz', 3: 'P3', 4: 'P4', 5: 'F7', 6: 'F8', 7: 'FC2', \n",
    "    8: 'FC3', 9: 'FC4', 10: 'FT7', 11: 'FT8', 12: 'Cz', 13: 'C3', 14: 'C4',\n",
    "    15: 'T3', 16: 'T4', 17: 'CPz', 18: 'CP3', 19: 'CP4', 20: 'TP7', 21: 'TP8',\n",
    "    22: 'Pz', 23: 'P3', 24: 'P4', 25: 'T5', 26: 'T6', 27: 'Oz', 28: 'O1',\n",
    "    29: 'O2', 30: 'HEOL', 31: 'VEOR', 32: 'Marker'\n",
    "}\n",
    "\n",
    "# Classify channels\n",
    "channels_all = [paper_channels[i] for i in range(33)]\n",
    "channels_eeg = [paper_channels[i] for i in range(30)]  # First 30 are EEG\n",
    "channels_eog = [paper_channels[30], paper_channels[31]]  # HEOL, VEOR\n",
    "channels_marker = [paper_channels[32]]  # Marker channel\n",
    "\n",
    "print(f\"Channels All: {len(channels_all)}\")\n",
    "print(f\"Channels EEG: {len(channels_eeg)}\")\n",
    "print(f\"Channels EOG: {len(channels_eog)}\")\n",
    "print(f\"Channels Marker: {len(channels_marker)}\")\n",
    "\n",
    "# ================= FUNCTION TO PROCESS ONE SUBJECT =================\n",
    "def process_preprocessed_edf_file(subject_id, raw_data_dir, preprocessed_dir, output_dir, sampling_rate=500):\n",
    "    \"\"\"\n",
    "    Process preprocessed .edf file for one subject and save in the specified format\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subject_id : str\n",
    "        Subject ID (e.g., '01', '02')\n",
    "    raw_data_dir : str\n",
    "        Directory containing raw .mat files\n",
    "    preprocessed_dir : str\n",
    "        Directory containing preprocessed .edf files\n",
    "    output_dir : str\n",
    "        Output directory for saved results\n",
    "    sampling_rate : int\n",
    "        Sampling rate in Hz (500 from paper)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    result_dict : dict\n",
    "        Dictionary with all required keys\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nProcessing preprocessed subject: {subject_id}\")\n",
    "    \n",
    "    # Construct file path for raw .mat file to get labels\n",
    "    mat_filename = f\"sub-{subject_id}_task-motor-imagery_eeg.mat\"\n",
    "    mat_path = os.path.join(raw_data_dir, mat_filename)\n",
    "    \n",
    "    if not os.path.exists(mat_path):\n",
    "        print(f\"  ‚ùå Raw .mat file not found: {mat_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load .mat file to get labels\n",
    "        data = loadmat(mat_path)\n",
    "        eeg_struct = data['eeg'][0, 0]\n",
    "        labels = eeg_struct['label'].flatten()  # Shape: (40,)\n",
    "        \n",
    "        print(f\"  ‚úì Loaded labels from .mat file: {labels.shape}\")\n",
    "        print(f\"    Left hand (1): {np.sum(labels == 1)}, Right hand (2): {np.sum(labels == 2)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error loading .mat file for {subject_id}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Construct preprocessed .edf file path\n",
    "    edf_filename = f\"sub-{subject_id}_task-motor-imagery_eeg.edf\"\n",
    "    edf_path = os.path.join(preprocessed_dir, edf_filename)\n",
    "    \n",
    "    if not os.path.exists(edf_path):\n",
    "        print(f\"  ‚ùå Preprocessed .edf file not found: {edf_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load .edf file\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
    "        data_edf, times = raw[:, :]\n",
    "        \n",
    "        print(f\"  ‚úì Loaded .edf data: {data_edf.shape}\")\n",
    "        print(f\"    Sampling rate: {raw.info['sfreq']} Hz\")\n",
    "        print(f\"    Duration: {raw.times[-1]:.2f} seconds\")\n",
    "        \n",
    "        # ================= SEGMENT THE CONTINUOUS DATA =================\n",
    "        # IMPORTANT: Based on debugging, the .edf files contain CONTINUOUS data\n",
    "        # Shape is (33, 160000) which is 320 seconds at 500Hz\n",
    "        # This is 40 trials √ó 8 seconds (2s instruction + 4s MI + 2s break)\n",
    "        # We need to extract only the 4s MI portion from each 8s trial\n",
    "        \n",
    "        file_sampling_rate = raw.info['sfreq']\n",
    "        n_trials = 40\n",
    "        \n",
    "        # Time parameters (in seconds)\n",
    "        instruction_duration = 2.0  # First 2 seconds to remove\n",
    "        mi_duration = 4.0  # Middle 4 seconds to keep\n",
    "        break_duration = 2.0  # Last 2 seconds to remove\n",
    "        trial_duration = instruction_duration + mi_duration + break_duration  # 8 seconds\n",
    "        \n",
    "        # Convert to samples\n",
    "        instruction_samples = int(instruction_duration * file_sampling_rate)\n",
    "        mi_samples = int(mi_duration * file_sampling_rate)\n",
    "        trial_samples = int(trial_duration * file_sampling_rate)\n",
    "        \n",
    "        print(f\"  ‚úì Segmenting continuous data:\")\n",
    "        print(f\"    - Total trials: {n_trials}\")\n",
    "        print(f\"    - Trial duration: {trial_duration}s = {trial_samples} samples\")\n",
    "        print(f\"    - MI portion: {mi_duration}s = {mi_samples} samples\")\n",
    "        print(f\"    - Total data available: {data_edf.shape[1]} samples\")\n",
    "        \n",
    "        # Check if we have enough data\n",
    "        total_samples_needed = n_trials * trial_samples\n",
    "        if data_edf.shape[1] < total_samples_needed:\n",
    "            print(f\"  ‚ùå Not enough data for {n_trials} trials\")\n",
    "            print(f\"    Need: {total_samples_needed} samples\")\n",
    "            print(f\"    Have: {data_edf.shape[1]} samples\")\n",
    "            return None\n",
    "        \n",
    "        # Extract MI segments from each trial\n",
    "        segments_mi_all = []\n",
    "        \n",
    "        for trial_idx in range(n_trials):\n",
    "            # Calculate sample indices for this trial's MI segment\n",
    "            trial_start = trial_idx * trial_samples\n",
    "            mi_start = trial_start + instruction_samples  # Skip 2s instruction\n",
    "            mi_end = mi_start + mi_samples  # 4s MI\n",
    "            \n",
    "            # Extract the MI segment (all channels)\n",
    "            mi_segment = data_edf[:, mi_start:mi_end]\n",
    "            segments_mi_all.append(mi_segment)\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        segments_mi_all = np.array(segments_mi_all)  # Shape: (n_trials, n_channels, mi_samples)\n",
    "        \n",
    "        # Extract EEG channels only (first 30 channels)\n",
    "        n_eeg_channels = min(30, segments_mi_all.shape[1])\n",
    "        segments_mi_eeg = segments_mi_all[:, :n_eeg_channels, :]\n",
    "        \n",
    "        print(f\"  ‚úì Segmented data:\")\n",
    "        print(f\"    - All channels shape: {segments_mi_all.shape}\")\n",
    "        print(f\"    - EEG only shape: {segments_mi_eeg.shape}\")\n",
    "        \n",
    "        # Create event_info DataFrame for Motor Imagery only\n",
    "        event_info = []\n",
    "        for trial_idx in range(n_trials):\n",
    "            label = labels[trial_idx]\n",
    "            hand = \"left\" if label == 1 else \"right\"\n",
    "            \n",
    "            # Calculate actual timing\n",
    "            trial_start_time = trial_idx * trial_duration\n",
    "            mi_start_time = trial_start_time + instruction_duration\n",
    "            \n",
    "            event_info.append({\n",
    "                'trial_idx': trial_idx,\n",
    "                'onset_sec': mi_start_time,\n",
    "                'duration_sec': mi_duration,\n",
    "                'label': label,\n",
    "                'hand': hand,\n",
    "                'condition': 'motor_imagery',\n",
    "                'sample_start': trial_idx * trial_samples + instruction_samples,\n",
    "                'sample_end': trial_idx * trial_samples + instruction_samples + mi_samples\n",
    "            })\n",
    "        \n",
    "        event_info_df = pd.DataFrame(event_info)\n",
    "        \n",
    "        # Create result dictionary with MI data only\n",
    "        result_dict = {\n",
    "            'segments_mi_all': segments_mi_all.astype(np.float32),  # Motor Imagery only, all channels\n",
    "            'segments_mi_eeg': segments_mi_eeg.astype(np.float32),  # Motor Imagery only, EEG channels\n",
    "            'labels': labels.astype(np.int32),\n",
    "            'channels_all': channels_all,\n",
    "            'channels_eeg': channels_eeg,\n",
    "            'channels_eog': channels_eog,\n",
    "            'channels_marker': channels_marker,\n",
    "            'sampling_rate': file_sampling_rate,\n",
    "            'subject_id': f\"sub-{subject_id}\",\n",
    "            'event_info': event_info_df.to_dict('records'),  # Save as list of dicts for JSON compatibility\n",
    "            'mi_info': {\n",
    "                'mi_duration_samples': mi_samples,\n",
    "                'mi_duration_seconds': mi_duration,\n",
    "                'trial_duration_seconds': trial_duration,\n",
    "                'n_trials': n_trials\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save to .npz file\n",
    "        output_path = os.path.join(output_dir, f\"sub-{subject_id}_preprocessed_motor_imagery.npz\")\n",
    "        np.savez_compressed(output_path, **result_dict)\n",
    "        \n",
    "        print(f\"  ‚úÖ Saved to: {output_path}\")\n",
    "        \n",
    "        # Print summary\n",
    "        left_count = np.sum(labels == 1)\n",
    "        right_count = np.sum(labels == 2)\n",
    "        print(f\"  üìä Summary: {left_count} left hand, {right_count} right hand trials\")\n",
    "        \n",
    "        return result_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error processing preprocessed file for {subject_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ================= PROCESS ALL SUBJECTS =================\n",
    "def process_all_preprocessed_subjects(raw_data_dir, preprocessed_dir, output_dir, max_subjects=None):\n",
    "    \"\"\"\n",
    "    Process all subjects in the preprocessed directory\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw_data_dir : str\n",
    "        Directory containing raw .mat files\n",
    "    preprocessed_dir : str\n",
    "        Directory containing preprocessed .edf files\n",
    "    output_dir : str\n",
    "        Output directory for saved results\n",
    "    max_subjects : int or None\n",
    "        Maximum number of subjects to process (for testing)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all .edf files\n",
    "    edf_files = [f for f in os.listdir(preprocessed_dir) if f.endswith('.edf')]\n",
    "    \n",
    "    # Sort by subject number\n",
    "    edf_files.sort(key=lambda x: int(x.split('-')[1].split('_')[0]))\n",
    "    \n",
    "    if max_subjects:\n",
    "        edf_files = edf_files[:max_subjects]\n",
    "    \n",
    "    print(f\"Found {len(edf_files)} preprocessed .edf files\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for edf_file in edf_files:\n",
    "        # Extract subject ID\n",
    "        subject_id = edf_file.split('-')[1].split('_')[0]  # Get '01' from 'sub-01_task-...'\n",
    "        \n",
    "        # Process this subject\n",
    "        result = process_preprocessed_edf_file(subject_id, raw_data_dir, preprocessed_dir, output_dir)\n",
    "        \n",
    "        if result:\n",
    "            all_results[subject_id] = result\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# ================= VERIFICATION FUNCTION =================\n",
    "def verify_saved_preprocessed_file(subject_id, output_dir):\n",
    "    \"\"\"\n",
    "    Verify that the saved file contains all required keys\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(output_dir, f\"sub-{subject_id}_preprocessed_motor_imagery.npz\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Load the file\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        \n",
    "        print(f\"\\nVerifying {os.path.basename(file_path)}:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Check all required keys\n",
    "        required_keys = [\n",
    "            'segments_mi_all', 'segments_mi_eeg', 'labels', 'channels_all',\n",
    "            'channels_eeg', 'channels_eog', 'channels_marker',\n",
    "            'sampling_rate', 'subject_id', 'event_info', 'mi_info'\n",
    "        ]\n",
    "        \n",
    "        all_present = True\n",
    "        for key in required_keys:\n",
    "            if key in data:\n",
    "                value = data[key]\n",
    "                if hasattr(value, 'shape'):\n",
    "                    print(f\"‚úì {key}: shape={value.shape}, dtype={value.dtype}\")\n",
    "                elif isinstance(value, dict):\n",
    "                    print(f\"‚úì {key}: dict\")\n",
    "                else:\n",
    "                    print(f\"‚úì {key}: {type(value)}\")\n",
    "            else:\n",
    "                print(f\"‚úó {key}: MISSING!\")\n",
    "                all_present = False\n",
    "        \n",
    "        # Print sample information\n",
    "        if 'labels' in data:\n",
    "            labels = data['labels']\n",
    "            print(f\"\\nLabel distribution:\")\n",
    "            print(f\"  Left hand (1): {np.sum(labels == 1)}\")\n",
    "            print(f\"  Right hand (2): {np.sum(labels == 2)}\")\n",
    "        \n",
    "        if 'segments_mi_eeg' in data:\n",
    "            segments = data['segments_mi_eeg']\n",
    "            print(f\"\\nMotor Imagery Segment information:\")\n",
    "            print(f\"  Shape: {segments.shape}\")\n",
    "            print(f\"  Trials: {segments.shape[0]}\")\n",
    "            print(f\"  Channels: {segments.shape[1]}\")\n",
    "            print(f\"  Samples per trial: {segments.shape[2]}\")\n",
    "            print(f\"  Duration per trial: {segments.shape[2] / data['sampling_rate']:.1f}s\")\n",
    "        \n",
    "        data.close()\n",
    "        return all_present\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying file: {e}\")\n",
    "        return False\n",
    "\n",
    "# ================= MAIN EXECUTION =================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PROCESSING PREPROCESSED .EDF FILES - MOTOR IMAGERY DATA ONLY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test with first 2 subjects\n",
    "    print(\"\\nTesting with first 2 subjects...\")\n",
    "    test_results = process_all_preprocessed_subjects(raw_data_dir, preprocessed_dir, output_dir, max_subjects=2)\n",
    "    \n",
    "    # Verify the saved files\n",
    "    if test_results:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"VERIFYING SAVED FILES\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for subject_id in list(test_results.keys())[:2]:\n",
    "            verify_saved_preprocessed_file(subject_id, output_dir)\n",
    "    \n",
    "    # Ask if user wants to process all subjects\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    response = input(\"Process ALL preprocessed subjects? (y/n): \")\n",
    "    \n",
    "    if response.lower() == 'y':\n",
    "        print(\"\\nProcessing all preprocessed subjects...\")\n",
    "        all_results = process_all_preprocessed_subjects(raw_data_dir, preprocessed_dir, output_dir)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"PROCESSING COMPLETE!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Results saved in: {output_dir}\")\n",
    "        print(f\"Files created:\")\n",
    "        \n",
    "        # List created files\n",
    "        created_files = os.listdir(output_dir)\n",
    "        for file in sorted(created_files):\n",
    "            if file.endswith('.npz'):\n",
    "                file_path = os.path.join(output_dir, file)\n",
    "                file_size = os.path.getsize(file_path) / 1024 / 1024\n",
    "                print(f\"  {file} ({file_size:.2f} MB)\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Processing stopped. Only test files were created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imenv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
